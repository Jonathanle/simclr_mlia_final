{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tckrXB2yn83S",
        "outputId": "57016ced-4f80-4f90-e614-179f0875fb2a"
      },
      "id": "tckrXB2yn83S",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5bede86c-5e05-4ff3-97aa-3e583e57a922",
      "metadata": {
        "id": "5bede86c-5e05-4ff3-97aa-3e583e57a922"
      },
      "outputs": [],
      "source": [
        "# Section 1: Import Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Section 2: Load and Preprocess Dataset\n",
        "train_images_path = \"/content/drive/MyDrive/Brain_images/brain_train_image_final.npy\"\n",
        "train_labels_path = \"/content/drive/MyDrive/Brain_images/brain_train_label.npy\"\n",
        "test_images_path = \"/content/drive/MyDrive/Brain_images/brain_test_image_final.npy\"\n",
        "test_labels_path = \"/content/drive/MyDrive/Brain_images/brain_test_label.npy\"\n",
        "\n",
        "# Load the data\n",
        "final_X_train_modified = np.load(train_images_path)[:, 1, :, :]\n",
        "final_X_test_modified = np.load(test_images_path)[:, 1, :, :]\n",
        "train_labels = np.load(train_labels_path)\n",
        "test_labels = np.load(test_labels_path)\n",
        "\n",
        "# Normalize and Resize Images using Pillow\n",
        "def normalize_and_resize(images, target_size=(224, 224)):\n",
        "    resized_images = []\n",
        "    for img in images:\n",
        "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
        "        resized_images.append(np.array(img_resized) / 255.0)\n",
        "    return np.array(resized_images)\n",
        "\n",
        "final_X_train_resized = normalize_and_resize(final_X_train_modified)\n",
        "final_X_test_resized = normalize_and_resize(final_X_test_modified)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fadd8664-e444-4860-861a-feb74186ebe2",
      "metadata": {
        "id": "fadd8664-e444-4860-861a-feb74186ebe2"
      },
      "outputs": [],
      "source": [
        "# Section 3: Define SimCLR Augmentation and Dataset\n",
        "transform_simclr = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.08, 1.0), ratio=(3/4, 4/3)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0))], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "class SimCLRDataset(Dataset):\n",
        "    def __init__(self, images, transform):\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        img_1 = self.transform(img)\n",
        "        img_2 = self.transform(img)\n",
        "        return img_1, img_2\n",
        "\n",
        "train_dataset = SimCLRDataset(final_X_train_resized, transform_simclr)\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c93eb44c-e269-4f61-b8f4-c044b1429cb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93eb44c-e269-4f61-b8f4-c044b1429cb1",
        "outputId": "c024fc6d-d4a7-400b-ddb6-4f8a81b64642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved image_0_aug1.png and image_0_aug2.png to augmented_images\n",
            "Saved image_1_aug1.png and image_1_aug2.png to augmented_images\n",
            "Saved image_2_aug1.png and image_2_aug2.png to augmented_images\n",
            "Saved image_3_aug1.png and image_3_aug2.png to augmented_images\n",
            "Saved image_4_aug1.png and image_4_aug2.png to augmented_images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Section 4: Save Augmented Images\n",
        "def save_augmented_images(dataset, save_dir=\"augmented_images\", num_images=5):\n",
        "    \"\"\"\n",
        "    Save a set of augmented images from the dataset to a directory.\n",
        "    \"\"\"\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        img_original = dataset.images[i]  # Original image\n",
        "        img_aug1, img_aug2 = dataset[i]  # Augmented pair\n",
        "\n",
        "        # Unnormalize images\n",
        "        img_aug1 = transforms.ToPILImage()(img_aug1 * 0.5 + 0.5)\n",
        "        img_aug2 = transforms.ToPILImage()(img_aug2 * 0.5 + 0.5)\n",
        "\n",
        "        # Save images\n",
        "        img_aug1.save(os.path.join(save_dir, f\"image_{i}_aug1.png\"))\n",
        "        img_aug2.save(os.path.join(save_dir, f\"image_{i}_aug2.png\"))\n",
        "\n",
        "        print(f\"Saved image_{i}_aug1.png and image_{i}_aug2.png to {save_dir}\")\n",
        "\n",
        "# Save augmented images from the training dataset\n",
        "save_augmented_images(train_dataset, save_dir=\"augmented_images\", num_images=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "87ae2a17-2cd0-4b34-a618-b3f36eb90f6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ae2a17-2cd0-4b34-a618-b3f36eb90f6b",
        "outputId": "3b9a03e1-ed92-4dc0-8f64-3df7daa321e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 189MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 7.8979\n",
            "Epoch [2/100], Loss: 6.7874\n",
            "Epoch [3/100], Loss: 6.6326\n",
            "Epoch [4/100], Loss: 6.5602\n",
            "Epoch [5/100], Loss: 6.5342\n",
            "Epoch [6/100], Loss: 6.4495\n",
            "Epoch [7/100], Loss: 6.3722\n",
            "Epoch [8/100], Loss: 6.3122\n",
            "Epoch [9/100], Loss: 6.2408\n",
            "Epoch [10/100], Loss: 6.2075\n",
            "Epoch [11/100], Loss: 6.1662\n",
            "Epoch [12/100], Loss: 6.0650\n",
            "Epoch [13/100], Loss: 5.9732\n",
            "Epoch [14/100], Loss: 5.8865\n",
            "Epoch [15/100], Loss: 5.7693\n",
            "Epoch [16/100], Loss: 5.6096\n",
            "Epoch [17/100], Loss: 5.5101\n",
            "Epoch [18/100], Loss: 5.3856\n",
            "Epoch [19/100], Loss: 5.2289\n",
            "Epoch [20/100], Loss: 5.1713\n",
            "Epoch [21/100], Loss: 5.0446\n",
            "Epoch [22/100], Loss: 4.8334\n",
            "Epoch [23/100], Loss: 4.7151\n",
            "Epoch [24/100], Loss: 4.6161\n",
            "Epoch [25/100], Loss: 4.4583\n",
            "Epoch [26/100], Loss: 4.4169\n",
            "Epoch [27/100], Loss: 4.2647\n",
            "Epoch [28/100], Loss: 4.1795\n",
            "Epoch [29/100], Loss: 4.1129\n",
            "Epoch [30/100], Loss: 4.0633\n",
            "Epoch [31/100], Loss: 3.8735\n",
            "Epoch [32/100], Loss: 3.8945\n",
            "Epoch [33/100], Loss: 3.7710\n",
            "Epoch [34/100], Loss: 3.6720\n",
            "Epoch [35/100], Loss: 3.7087\n",
            "Epoch [36/100], Loss: 3.6823\n",
            "Epoch [37/100], Loss: 3.5914\n",
            "Epoch [38/100], Loss: 3.4984\n",
            "Epoch [39/100], Loss: 3.5349\n",
            "Epoch [40/100], Loss: 3.3186\n",
            "Epoch [41/100], Loss: 3.3196\n",
            "Epoch [42/100], Loss: 3.4021\n",
            "Epoch [43/100], Loss: 3.3464\n",
            "Epoch [44/100], Loss: 3.2632\n",
            "Epoch [45/100], Loss: 3.2958\n",
            "Epoch [46/100], Loss: 3.1805\n",
            "Epoch [47/100], Loss: 3.2475\n",
            "Epoch [48/100], Loss: 3.0353\n",
            "Epoch [49/100], Loss: 3.2363\n",
            "Epoch [50/100], Loss: 2.9914\n",
            "Epoch [51/100], Loss: 3.0659\n",
            "Epoch [52/100], Loss: 3.0580\n",
            "Epoch [53/100], Loss: 2.9930\n",
            "Epoch [54/100], Loss: 2.8450\n",
            "Epoch [55/100], Loss: 2.8648\n",
            "Epoch [56/100], Loss: 2.8720\n",
            "Epoch [57/100], Loss: 2.9907\n",
            "Epoch [58/100], Loss: 2.8269\n",
            "Epoch [59/100], Loss: 2.9605\n",
            "Epoch [60/100], Loss: 2.7687\n",
            "Epoch [61/100], Loss: 2.7720\n",
            "Epoch [62/100], Loss: 2.8060\n",
            "Epoch [63/100], Loss: 2.7854\n",
            "Epoch [64/100], Loss: 2.7919\n",
            "Epoch [65/100], Loss: 2.7948\n",
            "Epoch [66/100], Loss: 2.8789\n",
            "Epoch [67/100], Loss: 2.8119\n",
            "Epoch [68/100], Loss: 2.7572\n",
            "Epoch [69/100], Loss: 2.7002\n",
            "Epoch [70/100], Loss: 2.7009\n",
            "Epoch [71/100], Loss: 2.7856\n",
            "Epoch [72/100], Loss: 2.6398\n",
            "Epoch [73/100], Loss: 2.6568\n",
            "Epoch [74/100], Loss: 2.7072\n",
            "Epoch [75/100], Loss: 2.5894\n",
            "Epoch [76/100], Loss: 2.6723\n",
            "Epoch [77/100], Loss: 2.6162\n",
            "Epoch [78/100], Loss: 2.4756\n",
            "Epoch [79/100], Loss: 2.5958\n",
            "Epoch [80/100], Loss: 2.5510\n",
            "Epoch [81/100], Loss: 2.4946\n",
            "Epoch [82/100], Loss: 2.5123\n",
            "Epoch [83/100], Loss: 2.6417\n",
            "Epoch [84/100], Loss: 2.6143\n",
            "Epoch [85/100], Loss: 2.5218\n",
            "Epoch [86/100], Loss: 2.5108\n",
            "Epoch [87/100], Loss: 2.5438\n",
            "Epoch [88/100], Loss: 2.5357\n",
            "Epoch [89/100], Loss: 2.4346\n",
            "Epoch [90/100], Loss: 2.4327\n",
            "Epoch [91/100], Loss: 2.5153\n",
            "Epoch [92/100], Loss: 2.4381\n",
            "Epoch [93/100], Loss: 2.4478\n",
            "Epoch [94/100], Loss: 2.5000\n",
            "Epoch [95/100], Loss: 2.4914\n",
            "Epoch [96/100], Loss: 2.4760\n",
            "Epoch [97/100], Loss: 2.3900\n",
            "Epoch [98/100], Loss: 2.4628\n",
            "Epoch [99/100], Loss: 2.4430\n",
            "Epoch [100/100], Loss: 2.4400\n"
          ]
        }
      ],
      "source": [
        "# Section 4: Define SimCLR Model and NT-Xent Loss\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_encoder, projection_dim):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = base_encoder\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, projection_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z = self.projector(h)\n",
        "        return z\n",
        "\n",
        "class NTXentLoss(nn.Module):\n",
        "    def __init__(self, batch_size, temperature):\n",
        "        super(NTXentLoss, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "        N = z_i.size(0) + z_j.size(0)\n",
        "        z = torch.cat((z_i, z_j), dim=0)\n",
        "        sim = torch.matmul(z, z.T) / self.temperature\n",
        "        mask = ~torch.eye(N, dtype=torch.bool, device=z.device)\n",
        "\n",
        "        positives = torch.cat([\n",
        "            torch.diag(sim, z_i.size(0)),\n",
        "            torch.diag(sim, -z_i.size(0))\n",
        "        ])\n",
        "\n",
        "        negatives = sim[mask].view(N, -1)\n",
        "        logits = torch.cat((positives.unsqueeze(1), negatives), dim=1)\n",
        "        labels = torch.zeros(N, dtype=torch.long, device=z.device)\n",
        "        loss = self.criterion(logits, labels) / N\n",
        "        return loss\n",
        "\n",
        "# Section 5: Initialize and Train SimCLR Model\n",
        "base_encoder = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "base_encoder.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "base_encoder.fc = nn.Identity()\n",
        "\n",
        "model = SimCLR(base_encoder, projection_dim=128).to(\"cuda\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = NTXentLoss(batch_size=128, temperature=0.5)\n",
        "\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for img_1, img_2 in train_loader:\n",
        "        img_1, img_2 = img_1.to(\"cuda\"), img_2.to(\"cuda\")\n",
        "        z_i = model(img_1)\n",
        "        z_j = model(img_2)\n",
        "\n",
        "        loss = criterion(z_i, z_j)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5328c7a4-7e4b-488d-bca6-d80fcfe8d01a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5328c7a4-7e4b-488d-bca6-d80fcfe8d01a",
        "outputId": "22327507-41d6-46df-e0eb-93642d22f476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained SimCLR model saved to simclr_pretrained_18_128.pth\n"
          ]
        }
      ],
      "source": [
        "# Section 6: Save the Pretrained SimCLR Model\n",
        "import os\n",
        "\n",
        "# Define the path to save the model\n",
        "save_path = \"simclr_pretrained_18_128.pth\"\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': epoch,\n",
        "    'loss': total_loss / len(train_loader)\n",
        "}, save_path)\n",
        "\n",
        "print(f\"Pretrained SimCLR model saved to {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the saved model\n",
        "files.download(\"simclr_pretrained_18_128.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18
        },
        "id": "U4Y4ktVkzfiS",
        "outputId": "26949d1e-eae3-4824-a8c8-709f08002bbb"
      },
      "id": "U4Y4ktVkzfiS",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dde01d25-f4ac-4c3a-b052-b50af7d9cb82\", \"simclr_pretrained_18_128.pth\", 136154618)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4a18a2ec-8bec-4512-a275-c928eadf8179",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a18a2ec-8bec-4512-a275-c928eadf8179",
        "outputId": "284413be-29b3-4733-d69b-6b31efec5fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 3.4910, Accuracy: 0.4400\n",
            "Epoch [2/100], Loss: 3.1022, Accuracy: 0.5341\n",
            "Epoch [3/100], Loss: 2.8545, Accuracy: 0.6041\n",
            "Epoch [4/100], Loss: 2.6496, Accuracy: 0.6415\n",
            "Epoch [5/100], Loss: 2.4624, Accuracy: 0.6807\n",
            "Epoch [6/100], Loss: 2.2080, Accuracy: 0.7399\n",
            "Epoch [7/100], Loss: 1.9389, Accuracy: 0.7761\n",
            "Epoch [8/100], Loss: 1.6699, Accuracy: 0.8346\n",
            "Epoch [9/100], Loss: 1.3650, Accuracy: 0.8835\n",
            "Epoch [10/100], Loss: 1.0929, Accuracy: 0.9203\n",
            "Epoch [11/100], Loss: 0.8647, Accuracy: 0.9499\n",
            "Epoch [12/100], Loss: 0.7448, Accuracy: 0.9620\n",
            "Epoch [13/100], Loss: 0.6528, Accuracy: 0.9716\n",
            "Epoch [14/100], Loss: 0.5611, Accuracy: 0.9825\n",
            "Epoch [15/100], Loss: 0.4798, Accuracy: 0.9873\n",
            "Epoch [16/100], Loss: 0.4163, Accuracy: 0.9891\n",
            "Epoch [17/100], Loss: 0.3533, Accuracy: 0.9909\n",
            "Epoch [18/100], Loss: 0.2988, Accuracy: 0.9958\n",
            "Epoch [19/100], Loss: 0.2520, Accuracy: 0.9976\n",
            "Epoch [20/100], Loss: 0.2245, Accuracy: 0.9976\n",
            "Epoch [21/100], Loss: 0.1862, Accuracy: 0.9982\n",
            "Epoch [22/100], Loss: 0.1736, Accuracy: 0.9982\n",
            "Epoch [23/100], Loss: 0.1610, Accuracy: 0.9988\n",
            "Epoch [24/100], Loss: 0.1499, Accuracy: 1.0000\n",
            "Epoch [25/100], Loss: 0.1381, Accuracy: 1.0000\n",
            "Epoch [26/100], Loss: 0.1342, Accuracy: 0.9994\n",
            "Epoch [27/100], Loss: 0.1202, Accuracy: 0.9994\n",
            "Epoch [28/100], Loss: 0.1142, Accuracy: 1.0000\n",
            "Epoch [29/100], Loss: 0.1106, Accuracy: 1.0000\n",
            "Epoch [30/100], Loss: 0.1006, Accuracy: 1.0000\n",
            "Epoch [31/100], Loss: 0.0944, Accuracy: 1.0000\n",
            "Epoch [32/100], Loss: 0.0936, Accuracy: 1.0000\n",
            "Epoch [33/100], Loss: 0.0920, Accuracy: 1.0000\n",
            "Epoch [34/100], Loss: 0.0821, Accuracy: 1.0000\n",
            "Epoch [35/100], Loss: 0.0778, Accuracy: 1.0000\n",
            "Epoch [36/100], Loss: 0.0804, Accuracy: 1.0000\n",
            "Epoch [37/100], Loss: 0.0731, Accuracy: 1.0000\n",
            "Epoch [38/100], Loss: 0.0765, Accuracy: 1.0000\n",
            "Epoch [39/100], Loss: 0.0726, Accuracy: 1.0000\n",
            "Epoch [40/100], Loss: 0.0690, Accuracy: 1.0000\n",
            "Epoch [41/100], Loss: 0.0681, Accuracy: 1.0000\n",
            "Epoch [42/100], Loss: 0.0718, Accuracy: 1.0000\n",
            "Epoch [43/100], Loss: 0.0668, Accuracy: 1.0000\n",
            "Epoch [44/100], Loss: 0.0678, Accuracy: 1.0000\n",
            "Epoch [45/100], Loss: 0.0725, Accuracy: 1.0000\n",
            "Epoch [46/100], Loss: 0.0687, Accuracy: 1.0000\n",
            "Epoch [47/100], Loss: 0.0612, Accuracy: 1.0000\n",
            "Epoch [48/100], Loss: 0.0658, Accuracy: 1.0000\n",
            "Epoch [49/100], Loss: 0.0598, Accuracy: 1.0000\n",
            "Epoch [50/100], Loss: 0.0612, Accuracy: 1.0000\n",
            "Epoch [51/100], Loss: 0.0584, Accuracy: 1.0000\n",
            "Epoch [52/100], Loss: 0.0587, Accuracy: 1.0000\n",
            "Epoch [53/100], Loss: 0.0586, Accuracy: 1.0000\n",
            "Epoch [54/100], Loss: 0.0563, Accuracy: 1.0000\n",
            "Epoch [55/100], Loss: 0.0554, Accuracy: 1.0000\n",
            "Epoch [56/100], Loss: 0.0556, Accuracy: 1.0000\n",
            "Epoch [57/100], Loss: 0.0557, Accuracy: 1.0000\n",
            "Epoch [58/100], Loss: 0.0542, Accuracy: 1.0000\n",
            "Epoch [59/100], Loss: 0.0543, Accuracy: 1.0000\n",
            "Epoch [60/100], Loss: 0.0540, Accuracy: 1.0000\n",
            "Epoch [61/100], Loss: 0.0534, Accuracy: 1.0000\n",
            "Epoch [62/100], Loss: 0.0542, Accuracy: 1.0000\n",
            "Epoch [63/100], Loss: 0.0515, Accuracy: 1.0000\n",
            "Epoch [64/100], Loss: 0.0544, Accuracy: 1.0000\n",
            "Epoch [65/100], Loss: 0.0619, Accuracy: 1.0000\n",
            "Epoch [66/100], Loss: 0.0541, Accuracy: 1.0000\n",
            "Epoch [67/100], Loss: 0.0527, Accuracy: 1.0000\n",
            "Epoch [68/100], Loss: 0.0533, Accuracy: 1.0000\n",
            "Epoch [69/100], Loss: 0.0523, Accuracy: 1.0000\n",
            "Epoch [70/100], Loss: 0.0530, Accuracy: 1.0000\n",
            "Epoch [71/100], Loss: 0.0511, Accuracy: 1.0000\n",
            "Epoch [72/100], Loss: 0.0519, Accuracy: 1.0000\n",
            "Epoch [73/100], Loss: 0.0506, Accuracy: 1.0000\n",
            "Epoch [74/100], Loss: 0.0501, Accuracy: 1.0000\n",
            "Epoch [75/100], Loss: 0.0542, Accuracy: 1.0000\n",
            "Epoch [76/100], Loss: 0.0521, Accuracy: 1.0000\n",
            "Epoch [77/100], Loss: 0.0507, Accuracy: 1.0000\n",
            "Epoch [78/100], Loss: 0.0518, Accuracy: 1.0000\n",
            "Epoch [79/100], Loss: 0.0537, Accuracy: 1.0000\n",
            "Epoch [80/100], Loss: 0.0517, Accuracy: 1.0000\n",
            "Epoch [81/100], Loss: 0.0512, Accuracy: 1.0000\n",
            "Epoch [82/100], Loss: 0.0509, Accuracy: 1.0000\n",
            "Epoch [83/100], Loss: 0.0495, Accuracy: 1.0000\n",
            "Epoch [84/100], Loss: 0.0509, Accuracy: 1.0000\n",
            "Epoch [85/100], Loss: 0.0497, Accuracy: 1.0000\n",
            "Epoch [86/100], Loss: 0.0518, Accuracy: 1.0000\n",
            "Epoch [87/100], Loss: 0.0502, Accuracy: 1.0000\n",
            "Epoch [88/100], Loss: 0.0557, Accuracy: 1.0000\n",
            "Epoch [89/100], Loss: 0.0477, Accuracy: 1.0000\n",
            "Epoch [90/100], Loss: 0.0502, Accuracy: 1.0000\n",
            "Epoch [91/100], Loss: 0.0518, Accuracy: 1.0000\n",
            "Epoch [92/100], Loss: 0.0492, Accuracy: 1.0000\n",
            "Epoch [93/100], Loss: 0.0476, Accuracy: 1.0000\n",
            "Epoch [94/100], Loss: 0.0498, Accuracy: 1.0000\n",
            "Epoch [95/100], Loss: 0.0497, Accuracy: 1.0000\n",
            "Epoch [96/100], Loss: 0.0509, Accuracy: 1.0000\n",
            "Epoch [97/100], Loss: 0.0484, Accuracy: 1.0000\n",
            "Epoch [98/100], Loss: 0.0502, Accuracy: 1.0000\n",
            "Epoch [99/100], Loss: 0.0516, Accuracy: 1.0000\n",
            "Epoch [100/100], Loss: 0.0491, Accuracy: 1.0000\n",
            "Test Accuracy%: 90.1024\n"
          ]
        }
      ],
      "source": [
        "# Section 7: Define Classification Dataset and Head\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_dataset = TestDataset(final_X_train_resized, train_labels, transform=train_transform)\n",
        "test_dataset = TestDataset(final_X_test_resized, test_labels, transform=test_transform)\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "classification_head = ClassificationHead(input_dim=512, num_classes=len(np.unique(train_labels))).to(\"cuda\")\n",
        "\n",
        "# Section 8: Fine-tune and Evaluate Classification Model\n",
        "optimizer_cls = optim.Adam([\n",
        "    {\"params\": model.encoder.parameters(), \"lr\": 1e-5},\n",
        "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},\n",
        "])\n",
        "scheduler_cls = StepLR(optimizer_cls, step_size=10, gamma=0.5)\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "\n",
        "# Fine-tune\n",
        "for epoch in range(100):\n",
        "    model.encoder.train()\n",
        "    classification_head.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for img, label in DataLoader(train_dataset, batch_size=128, shuffle=True):\n",
        "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
        "        features = model.encoder(img)\n",
        "        logits = classification_head(features)\n",
        "        loss = criterion_cls(logits, label)\n",
        "\n",
        "        optimizer_cls.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_cls.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
        "\n",
        "    accuracy = correct / len(train_labels)\n",
        "    scheduler_cls.step()\n",
        "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "classification_head.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for img, label in DataLoader(test_dataset, batch_size=128, shuffle=False):\n",
        "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
        "        features = model.encoder(img)\n",
        "        logits = classification_head(features)\n",
        "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
        "\n",
        "test_accuracy = correct / len(test_labels)\n",
        "print(f\"Test Accuracy%: {test_accuracy*100:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qF0FR1lz4Lk"
      },
      "id": "6qF0FR1lz4Lk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch 2.4.0",
      "language": "python",
      "name": "pytorch-2.4.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}