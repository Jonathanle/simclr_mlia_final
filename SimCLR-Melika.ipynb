{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "efd0fcac-1a5c-4ab4-aa79-440819515c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 6.5709\n",
      "Epoch [2/200], Loss: 6.5706\n",
      "Epoch [3/200], Loss: 6.5707\n",
      "Epoch [4/200], Loss: 6.5706\n",
      "Epoch [5/200], Loss: 6.5701\n",
      "Epoch [6/200], Loss: 6.5705\n",
      "Epoch [7/200], Loss: 6.5702\n",
      "Epoch [8/200], Loss: 6.5697\n",
      "Epoch [9/200], Loss: 6.5709\n",
      "Epoch [10/200], Loss: 6.5707\n",
      "Epoch [11/200], Loss: 6.5702\n",
      "Epoch [12/200], Loss: 6.5701\n",
      "Epoch [13/200], Loss: 6.5695\n",
      "Epoch [14/200], Loss: 6.5705\n",
      "Epoch [15/200], Loss: 6.5681\n",
      "Epoch [16/200], Loss: 6.5699\n",
      "Epoch [17/200], Loss: 6.5707\n",
      "Epoch [18/200], Loss: 6.5680\n",
      "Epoch [19/200], Loss: 6.5694\n",
      "Epoch [20/200], Loss: 6.5713\n",
      "Epoch [21/200], Loss: 6.5699\n",
      "Epoch [22/200], Loss: 6.5698\n",
      "Epoch [23/200], Loss: 6.5686\n",
      "Epoch [24/200], Loss: 6.5693\n",
      "Epoch [25/200], Loss: 6.5689\n",
      "Epoch [26/200], Loss: 6.5694\n",
      "Epoch [27/200], Loss: 6.5696\n",
      "Epoch [28/200], Loss: 6.5675\n",
      "Epoch [29/200], Loss: 6.5700\n",
      "Epoch [30/200], Loss: 6.5675\n",
      "Epoch [31/200], Loss: 6.5684\n",
      "Epoch [32/200], Loss: 6.5662\n",
      "Epoch [33/200], Loss: 6.5646\n",
      "Epoch [34/200], Loss: 6.5655\n",
      "Epoch [35/200], Loss: 6.5703\n",
      "Epoch [36/200], Loss: 6.5645\n",
      "Epoch [37/200], Loss: 6.5679\n",
      "Epoch [38/200], Loss: 6.5665\n",
      "Epoch [39/200], Loss: 6.5703\n",
      "Epoch [40/200], Loss: 6.5681\n",
      "Epoch [41/200], Loss: 6.5673\n",
      "Epoch [42/200], Loss: 6.5662\n",
      "Epoch [43/200], Loss: 6.5672\n",
      "Epoch [44/200], Loss: 6.5647\n",
      "Epoch [45/200], Loss: 6.5694\n",
      "Epoch [46/200], Loss: 6.5662\n",
      "Epoch [47/200], Loss: 6.5647\n",
      "Epoch [48/200], Loss: 6.5637\n",
      "Epoch [49/200], Loss: 6.5633\n",
      "Epoch [50/200], Loss: 6.5641\n",
      "Epoch [51/200], Loss: 6.5626\n",
      "Epoch [52/200], Loss: 6.5628\n",
      "Epoch [53/200], Loss: 6.5665\n",
      "Epoch [54/200], Loss: 6.5642\n",
      "Epoch [55/200], Loss: 6.5630\n",
      "Epoch [56/200], Loss: 6.5630\n",
      "Epoch [57/200], Loss: 6.5639\n",
      "Epoch [58/200], Loss: 6.5601\n",
      "Epoch [59/200], Loss: 6.5646\n",
      "Epoch [60/200], Loss: 6.5605\n",
      "Epoch [61/200], Loss: 6.5604\n",
      "Epoch [62/200], Loss: 6.5647\n",
      "Epoch [63/200], Loss: 6.5641\n",
      "Epoch [64/200], Loss: 6.5651\n",
      "Epoch [65/200], Loss: 6.5653\n",
      "Epoch [66/200], Loss: 6.5565\n",
      "Epoch [67/200], Loss: 6.5648\n",
      "Epoch [68/200], Loss: 6.5614\n",
      "Epoch [69/200], Loss: 6.5624\n",
      "Epoch [70/200], Loss: 6.5590\n",
      "Epoch [71/200], Loss: 6.5598\n",
      "Epoch [72/200], Loss: 6.5632\n",
      "Epoch [73/200], Loss: 6.5603\n",
      "Epoch [74/200], Loss: 6.5619\n",
      "Epoch [75/200], Loss: 6.5584\n",
      "Epoch [76/200], Loss: 6.5583\n",
      "Epoch [77/200], Loss: 6.5595\n",
      "Epoch [78/200], Loss: 6.5615\n",
      "Epoch [79/200], Loss: 6.5643\n",
      "Epoch [80/200], Loss: 6.5577\n",
      "Epoch [81/200], Loss: 6.5569\n",
      "Epoch [82/200], Loss: 6.5632\n",
      "Epoch [83/200], Loss: 6.5612\n",
      "Epoch [84/200], Loss: 6.5611\n",
      "Epoch [85/200], Loss: 6.5584\n",
      "Epoch [86/200], Loss: 6.5585\n",
      "Epoch [87/200], Loss: 6.5570\n",
      "Epoch [88/200], Loss: 6.5574\n",
      "Epoch [89/200], Loss: 6.5576\n",
      "Epoch [90/200], Loss: 6.5558\n",
      "Epoch [91/200], Loss: 6.5620\n",
      "Epoch [92/200], Loss: 6.5633\n",
      "Epoch [93/200], Loss: 6.5560\n",
      "Epoch [94/200], Loss: 6.5605\n",
      "Epoch [95/200], Loss: 6.5570\n",
      "Epoch [96/200], Loss: 6.5574\n",
      "Epoch [97/200], Loss: 6.5534\n",
      "Epoch [98/200], Loss: 6.5541\n",
      "Epoch [99/200], Loss: 6.5591\n",
      "Epoch [100/200], Loss: 6.5530\n",
      "Epoch [101/200], Loss: 6.5599\n",
      "Epoch [102/200], Loss: 6.5609\n",
      "Epoch [103/200], Loss: 6.5527\n",
      "Epoch [104/200], Loss: 6.5547\n",
      "Epoch [105/200], Loss: 6.5570\n",
      "Epoch [106/200], Loss: 6.5513\n",
      "Epoch [107/200], Loss: 6.5607\n",
      "Epoch [108/200], Loss: 6.5504\n",
      "Epoch [109/200], Loss: 6.5558\n",
      "Epoch [110/200], Loss: 6.5547\n",
      "Epoch [111/200], Loss: 6.5527\n",
      "Epoch [112/200], Loss: 6.5479\n",
      "Epoch [113/200], Loss: 6.5498\n",
      "Epoch [114/200], Loss: 6.5542\n",
      "Epoch [115/200], Loss: 6.5457\n",
      "Epoch [116/200], Loss: 6.5486\n",
      "Epoch [117/200], Loss: 6.5541\n",
      "Epoch [118/200], Loss: 6.5536\n",
      "Epoch [119/200], Loss: 6.5499\n",
      "Epoch [120/200], Loss: 6.5586\n",
      "Epoch [121/200], Loss: 6.5513\n",
      "Epoch [122/200], Loss: 6.5432\n",
      "Epoch [123/200], Loss: 6.5545\n",
      "Epoch [124/200], Loss: 6.5458\n",
      "Epoch [125/200], Loss: 6.5540\n",
      "Epoch [126/200], Loss: 6.5486\n",
      "Epoch [127/200], Loss: 6.5502\n",
      "Epoch [128/200], Loss: 6.5510\n",
      "Epoch [129/200], Loss: 6.5560\n",
      "Epoch [130/200], Loss: 6.5487\n",
      "Epoch [131/200], Loss: 6.5411\n",
      "Epoch [132/200], Loss: 6.5472\n",
      "Epoch [133/200], Loss: 6.5420\n",
      "Epoch [134/200], Loss: 6.5432\n",
      "Epoch [135/200], Loss: 6.5447\n",
      "Epoch [136/200], Loss: 6.5569\n",
      "Epoch [137/200], Loss: 6.5452\n",
      "Epoch [138/200], Loss: 6.5460\n",
      "Epoch [139/200], Loss: 6.5426\n",
      "Epoch [140/200], Loss: 6.5481\n",
      "Epoch [141/200], Loss: 6.5446\n",
      "Epoch [142/200], Loss: 6.5439\n",
      "Epoch [143/200], Loss: 6.5442\n",
      "Epoch [144/200], Loss: 6.5475\n",
      "Epoch [145/200], Loss: 6.5420\n",
      "Epoch [146/200], Loss: 6.5437\n",
      "Epoch [147/200], Loss: 6.5455\n",
      "Epoch [148/200], Loss: 6.5435\n",
      "Epoch [149/200], Loss: 6.5447\n",
      "Epoch [150/200], Loss: 6.5454\n",
      "Epoch [151/200], Loss: 6.5403\n",
      "Epoch [152/200], Loss: 6.5518\n",
      "Epoch [153/200], Loss: 6.5413\n",
      "Epoch [154/200], Loss: 6.5394\n",
      "Epoch [155/200], Loss: 6.5425\n",
      "Epoch [156/200], Loss: 6.5478\n",
      "Epoch [157/200], Loss: 6.5336\n",
      "Epoch [158/200], Loss: 6.5423\n",
      "Epoch [159/200], Loss: 6.5422\n",
      "Epoch [160/200], Loss: 6.5465\n",
      "Epoch [161/200], Loss: 6.5481\n",
      "Epoch [162/200], Loss: 6.5467\n",
      "Epoch [163/200], Loss: 6.5503\n",
      "Epoch [164/200], Loss: 6.5479\n",
      "Epoch [165/200], Loss: 6.5400\n",
      "Epoch [166/200], Loss: 6.5429\n",
      "Epoch [167/200], Loss: 6.5345\n",
      "Epoch [168/200], Loss: 6.5426\n",
      "Epoch [169/200], Loss: 6.5490\n",
      "Epoch [170/200], Loss: 6.5451\n",
      "Epoch [171/200], Loss: 6.5454\n",
      "Epoch [172/200], Loss: 6.5424\n",
      "Epoch [173/200], Loss: 6.5448\n",
      "Epoch [174/200], Loss: 6.5432\n",
      "Epoch [175/200], Loss: 6.5373\n",
      "Epoch [176/200], Loss: 6.5441\n",
      "Epoch [177/200], Loss: 6.5397\n",
      "Epoch [178/200], Loss: 6.5386\n",
      "Epoch [179/200], Loss: 6.5363\n",
      "Epoch [180/200], Loss: 6.5465\n",
      "Epoch [181/200], Loss: 6.5338\n",
      "Epoch [182/200], Loss: 6.5341\n",
      "Epoch [183/200], Loss: 6.5340\n",
      "Epoch [184/200], Loss: 6.5424\n",
      "Epoch [185/200], Loss: 6.5399\n",
      "Epoch [186/200], Loss: 6.5413\n",
      "Epoch [187/200], Loss: 6.5416\n",
      "Epoch [188/200], Loss: 6.5468\n",
      "Epoch [189/200], Loss: 6.5374\n",
      "Epoch [190/200], Loss: 6.5511\n",
      "Epoch [191/200], Loss: 6.5361\n",
      "Epoch [192/200], Loss: 6.5365\n",
      "Epoch [193/200], Loss: 6.5403\n",
      "Epoch [194/200], Loss: 6.5303\n",
      "Epoch [195/200], Loss: 6.5294\n",
      "Epoch [196/200], Loss: 6.5399\n",
      "Epoch [197/200], Loss: 6.5366\n",
      "Epoch [198/200], Loss: 6.5266\n",
      "Epoch [199/200], Loss: 6.5291\n",
      "Epoch [200/200], Loss: 6.5260\n",
      "Epoch [1/100], Loss: 0.0168, Accuracy: 0.4080\n",
      "Epoch [2/100], Loss: 0.0164, Accuracy: 0.4454\n",
      "Epoch [3/100], Loss: 0.0162, Accuracy: 0.4454\n",
      "Epoch [4/100], Loss: 0.0161, Accuracy: 0.4484\n",
      "Epoch [5/100], Loss: 0.0161, Accuracy: 0.4454\n",
      "Epoch [6/100], Loss: 0.0160, Accuracy: 0.4581\n",
      "Epoch [7/100], Loss: 0.0160, Accuracy: 0.4454\n",
      "Epoch [8/100], Loss: 0.0160, Accuracy: 0.4544\n",
      "Epoch [9/100], Loss: 0.0160, Accuracy: 0.4550\n",
      "Epoch [10/100], Loss: 0.0159, Accuracy: 0.4599\n",
      "Epoch [11/100], Loss: 0.0159, Accuracy: 0.4587\n",
      "Epoch [12/100], Loss: 0.0159, Accuracy: 0.4677\n",
      "Epoch [13/100], Loss: 0.0159, Accuracy: 0.4635\n",
      "Epoch [14/100], Loss: 0.0159, Accuracy: 0.4581\n",
      "Epoch [15/100], Loss: 0.0158, Accuracy: 0.4786\n",
      "Epoch [16/100], Loss: 0.0158, Accuracy: 0.4792\n",
      "Epoch [17/100], Loss: 0.0158, Accuracy: 0.4816\n",
      "Epoch [18/100], Loss: 0.0157, Accuracy: 0.4804\n",
      "Epoch [19/100], Loss: 0.0157, Accuracy: 0.4912\n",
      "Epoch [20/100], Loss: 0.0157, Accuracy: 0.4828\n",
      "Epoch [21/100], Loss: 0.0157, Accuracy: 0.4810\n",
      "Epoch [22/100], Loss: 0.0156, Accuracy: 0.4882\n",
      "Epoch [23/100], Loss: 0.0156, Accuracy: 0.4955\n",
      "Epoch [24/100], Loss: 0.0156, Accuracy: 0.4882\n",
      "Epoch [25/100], Loss: 0.0156, Accuracy: 0.5069\n",
      "Epoch [26/100], Loss: 0.0156, Accuracy: 0.4949\n",
      "Epoch [27/100], Loss: 0.0156, Accuracy: 0.5027\n",
      "Epoch [28/100], Loss: 0.0155, Accuracy: 0.5124\n",
      "Epoch [29/100], Loss: 0.0155, Accuracy: 0.5027\n",
      "Epoch [30/100], Loss: 0.0155, Accuracy: 0.5045\n",
      "Epoch [31/100], Loss: 0.0155, Accuracy: 0.5063\n",
      "Epoch [32/100], Loss: 0.0154, Accuracy: 0.5142\n",
      "Epoch [33/100], Loss: 0.0154, Accuracy: 0.5160\n",
      "Epoch [34/100], Loss: 0.0154, Accuracy: 0.5172\n",
      "Epoch [35/100], Loss: 0.0154, Accuracy: 0.5208\n",
      "Epoch [36/100], Loss: 0.0154, Accuracy: 0.5124\n",
      "Epoch [37/100], Loss: 0.0153, Accuracy: 0.5238\n",
      "Epoch [38/100], Loss: 0.0153, Accuracy: 0.5130\n",
      "Epoch [39/100], Loss: 0.0153, Accuracy: 0.5359\n",
      "Epoch [40/100], Loss: 0.0153, Accuracy: 0.5202\n",
      "Epoch [41/100], Loss: 0.0153, Accuracy: 0.5293\n",
      "Epoch [42/100], Loss: 0.0152, Accuracy: 0.5444\n",
      "Epoch [43/100], Loss: 0.0153, Accuracy: 0.5075\n",
      "Epoch [44/100], Loss: 0.0152, Accuracy: 0.5269\n",
      "Epoch [45/100], Loss: 0.0152, Accuracy: 0.5401\n",
      "Epoch [46/100], Loss: 0.0152, Accuracy: 0.5232\n",
      "Epoch [47/100], Loss: 0.0151, Accuracy: 0.5425\n",
      "Epoch [48/100], Loss: 0.0151, Accuracy: 0.5377\n",
      "Epoch [49/100], Loss: 0.0151, Accuracy: 0.5395\n",
      "Epoch [50/100], Loss: 0.0151, Accuracy: 0.5353\n",
      "Epoch [51/100], Loss: 0.0151, Accuracy: 0.5456\n",
      "Epoch [52/100], Loss: 0.0150, Accuracy: 0.5450\n",
      "Epoch [53/100], Loss: 0.0150, Accuracy: 0.5594\n",
      "Epoch [54/100], Loss: 0.0150, Accuracy: 0.5468\n",
      "Epoch [55/100], Loss: 0.0150, Accuracy: 0.5456\n",
      "Epoch [56/100], Loss: 0.0150, Accuracy: 0.5486\n",
      "Epoch [57/100], Loss: 0.0150, Accuracy: 0.5468\n",
      "Epoch [58/100], Loss: 0.0149, Accuracy: 0.5619\n",
      "Epoch [59/100], Loss: 0.0149, Accuracy: 0.5504\n",
      "Epoch [60/100], Loss: 0.0149, Accuracy: 0.5564\n",
      "Epoch [61/100], Loss: 0.0149, Accuracy: 0.5649\n",
      "Epoch [62/100], Loss: 0.0149, Accuracy: 0.5673\n",
      "Epoch [63/100], Loss: 0.0148, Accuracy: 0.5631\n",
      "Epoch [64/100], Loss: 0.0149, Accuracy: 0.5625\n",
      "Epoch [65/100], Loss: 0.0149, Accuracy: 0.5582\n",
      "Epoch [66/100], Loss: 0.0148, Accuracy: 0.5576\n",
      "Epoch [67/100], Loss: 0.0148, Accuracy: 0.5739\n",
      "Epoch [68/100], Loss: 0.0148, Accuracy: 0.5788\n",
      "Epoch [69/100], Loss: 0.0148, Accuracy: 0.5613\n",
      "Epoch [70/100], Loss: 0.0147, Accuracy: 0.5733\n",
      "Epoch [71/100], Loss: 0.0147, Accuracy: 0.5673\n",
      "Epoch [72/100], Loss: 0.0147, Accuracy: 0.5709\n",
      "Epoch [73/100], Loss: 0.0147, Accuracy: 0.5782\n",
      "Epoch [74/100], Loss: 0.0147, Accuracy: 0.5769\n",
      "Epoch [75/100], Loss: 0.0147, Accuracy: 0.5709\n",
      "Epoch [76/100], Loss: 0.0146, Accuracy: 0.5812\n",
      "Epoch [77/100], Loss: 0.0146, Accuracy: 0.5872\n",
      "Epoch [78/100], Loss: 0.0146, Accuracy: 0.5818\n",
      "Epoch [79/100], Loss: 0.0146, Accuracy: 0.5818\n",
      "Epoch [80/100], Loss: 0.0146, Accuracy: 0.5842\n",
      "Epoch [81/100], Loss: 0.0146, Accuracy: 0.5957\n",
      "Epoch [82/100], Loss: 0.0146, Accuracy: 0.5854\n",
      "Epoch [83/100], Loss: 0.0145, Accuracy: 0.5824\n",
      "Epoch [84/100], Loss: 0.0145, Accuracy: 0.5788\n",
      "Epoch [85/100], Loss: 0.0145, Accuracy: 0.5715\n",
      "Epoch [86/100], Loss: 0.0145, Accuracy: 0.5860\n",
      "Epoch [87/100], Loss: 0.0145, Accuracy: 0.5896\n",
      "Epoch [88/100], Loss: 0.0144, Accuracy: 0.5920\n",
      "Epoch [89/100], Loss: 0.0144, Accuracy: 0.5872\n",
      "Epoch [90/100], Loss: 0.0145, Accuracy: 0.5926\n",
      "Epoch [91/100], Loss: 0.0144, Accuracy: 0.5926\n",
      "Epoch [92/100], Loss: 0.0144, Accuracy: 0.5721\n",
      "Epoch [93/100], Loss: 0.0144, Accuracy: 0.5884\n",
      "Epoch [94/100], Loss: 0.0144, Accuracy: 0.6017\n",
      "Epoch [95/100], Loss: 0.0144, Accuracy: 0.5951\n",
      "Epoch [96/100], Loss: 0.0144, Accuracy: 0.5920\n",
      "Epoch [97/100], Loss: 0.0143, Accuracy: 0.5902\n",
      "Epoch [98/100], Loss: 0.0144, Accuracy: 0.5854\n",
      "Epoch [99/100], Loss: 0.0143, Accuracy: 0.5963\n",
      "Epoch [100/100], Loss: 0.0143, Accuracy: 0.6011\n",
      "Epoch [101/100], Loss: 0.0143, Accuracy: 0.5951\n",
      "Epoch [102/100], Loss: 0.0143, Accuracy: 0.6126\n",
      "Epoch [103/100], Loss: 0.0142, Accuracy: 0.6005\n",
      "Epoch [104/100], Loss: 0.0142, Accuracy: 0.5969\n",
      "Epoch [105/100], Loss: 0.0142, Accuracy: 0.5944\n",
      "Epoch [106/100], Loss: 0.0143, Accuracy: 0.5782\n",
      "Epoch [107/100], Loss: 0.0142, Accuracy: 0.6089\n",
      "Epoch [108/100], Loss: 0.0142, Accuracy: 0.5987\n",
      "Epoch [109/100], Loss: 0.0142, Accuracy: 0.6095\n",
      "Epoch [110/100], Loss: 0.0142, Accuracy: 0.6126\n",
      "Epoch [111/100], Loss: 0.0142, Accuracy: 0.5944\n",
      "Epoch [112/100], Loss: 0.0142, Accuracy: 0.5908\n",
      "Epoch [113/100], Loss: 0.0142, Accuracy: 0.6011\n",
      "Epoch [114/100], Loss: 0.0141, Accuracy: 0.6083\n",
      "Epoch [115/100], Loss: 0.0141, Accuracy: 0.6005\n",
      "Epoch [116/100], Loss: 0.0142, Accuracy: 0.6071\n",
      "Epoch [117/100], Loss: 0.0141, Accuracy: 0.6017\n",
      "Epoch [118/100], Loss: 0.0141, Accuracy: 0.6138\n",
      "Epoch [119/100], Loss: 0.0141, Accuracy: 0.6053\n",
      "Epoch [120/100], Loss: 0.0141, Accuracy: 0.5908\n",
      "Epoch [121/100], Loss: 0.0140, Accuracy: 0.6023\n",
      "Epoch [122/100], Loss: 0.0140, Accuracy: 0.6192\n",
      "Epoch [123/100], Loss: 0.0140, Accuracy: 0.6210\n",
      "Epoch [124/100], Loss: 0.0140, Accuracy: 0.6101\n",
      "Epoch [125/100], Loss: 0.0140, Accuracy: 0.6204\n",
      "Epoch [126/100], Loss: 0.0139, Accuracy: 0.6186\n",
      "Epoch [127/100], Loss: 0.0140, Accuracy: 0.6174\n",
      "Epoch [128/100], Loss: 0.0139, Accuracy: 0.6174\n",
      "Epoch [129/100], Loss: 0.0139, Accuracy: 0.6168\n",
      "Epoch [130/100], Loss: 0.0139, Accuracy: 0.6107\n",
      "Epoch [131/100], Loss: 0.0139, Accuracy: 0.6222\n",
      "Epoch [132/100], Loss: 0.0139, Accuracy: 0.6186\n",
      "Epoch [133/100], Loss: 0.0139, Accuracy: 0.6282\n",
      "Epoch [134/100], Loss: 0.0139, Accuracy: 0.6228\n",
      "Epoch [135/100], Loss: 0.0139, Accuracy: 0.6258\n",
      "Epoch [136/100], Loss: 0.0139, Accuracy: 0.6198\n",
      "Epoch [137/100], Loss: 0.0138, Accuracy: 0.6276\n",
      "Epoch [138/100], Loss: 0.0138, Accuracy: 0.6198\n",
      "Epoch [139/100], Loss: 0.0138, Accuracy: 0.6216\n",
      "Epoch [140/100], Loss: 0.0138, Accuracy: 0.6246\n",
      "Epoch [141/100], Loss: 0.0138, Accuracy: 0.6246\n",
      "Epoch [142/100], Loss: 0.0138, Accuracy: 0.6282\n",
      "Epoch [143/100], Loss: 0.0138, Accuracy: 0.6234\n",
      "Epoch [144/100], Loss: 0.0137, Accuracy: 0.6288\n",
      "Epoch [145/100], Loss: 0.0138, Accuracy: 0.6246\n",
      "Epoch [146/100], Loss: 0.0137, Accuracy: 0.6282\n",
      "Epoch [147/100], Loss: 0.0137, Accuracy: 0.6307\n",
      "Epoch [148/100], Loss: 0.0137, Accuracy: 0.6270\n",
      "Epoch [149/100], Loss: 0.0137, Accuracy: 0.6234\n",
      "Epoch [150/100], Loss: 0.0137, Accuracy: 0.6337\n",
      "Epoch [151/100], Loss: 0.0137, Accuracy: 0.6258\n",
      "Epoch [152/100], Loss: 0.0136, Accuracy: 0.6349\n",
      "Epoch [153/100], Loss: 0.0137, Accuracy: 0.6307\n",
      "Epoch [154/100], Loss: 0.0136, Accuracy: 0.6319\n",
      "Epoch [155/100], Loss: 0.0136, Accuracy: 0.6295\n",
      "Epoch [156/100], Loss: 0.0137, Accuracy: 0.6216\n",
      "Epoch [157/100], Loss: 0.0136, Accuracy: 0.6252\n",
      "Epoch [158/100], Loss: 0.0136, Accuracy: 0.6282\n",
      "Epoch [159/100], Loss: 0.0136, Accuracy: 0.6343\n",
      "Epoch [160/100], Loss: 0.0136, Accuracy: 0.6415\n",
      "Epoch [161/100], Loss: 0.0136, Accuracy: 0.6288\n",
      "Epoch [162/100], Loss: 0.0136, Accuracy: 0.6367\n",
      "Epoch [163/100], Loss: 0.0136, Accuracy: 0.6198\n",
      "Epoch [164/100], Loss: 0.0135, Accuracy: 0.6325\n",
      "Epoch [165/100], Loss: 0.0135, Accuracy: 0.6349\n",
      "Epoch [166/100], Loss: 0.0135, Accuracy: 0.6391\n",
      "Epoch [167/100], Loss: 0.0135, Accuracy: 0.6343\n",
      "Epoch [168/100], Loss: 0.0135, Accuracy: 0.6397\n",
      "Epoch [169/100], Loss: 0.0135, Accuracy: 0.6337\n",
      "Epoch [170/100], Loss: 0.0135, Accuracy: 0.6367\n",
      "Epoch [171/100], Loss: 0.0135, Accuracy: 0.6439\n",
      "Epoch [172/100], Loss: 0.0135, Accuracy: 0.6385\n",
      "Epoch [173/100], Loss: 0.0135, Accuracy: 0.6488\n",
      "Epoch [174/100], Loss: 0.0134, Accuracy: 0.6433\n",
      "Epoch [175/100], Loss: 0.0134, Accuracy: 0.6421\n",
      "Epoch [176/100], Loss: 0.0134, Accuracy: 0.6397\n",
      "Epoch [177/100], Loss: 0.0134, Accuracy: 0.6403\n",
      "Epoch [178/100], Loss: 0.0134, Accuracy: 0.6463\n",
      "Epoch [179/100], Loss: 0.0134, Accuracy: 0.6445\n",
      "Epoch [180/100], Loss: 0.0134, Accuracy: 0.6415\n",
      "Epoch [181/100], Loss: 0.0134, Accuracy: 0.6373\n",
      "Epoch [182/100], Loss: 0.0134, Accuracy: 0.6457\n",
      "Epoch [183/100], Loss: 0.0134, Accuracy: 0.6470\n",
      "Epoch [184/100], Loss: 0.0133, Accuracy: 0.6518\n",
      "Epoch [185/100], Loss: 0.0133, Accuracy: 0.6445\n",
      "Epoch [186/100], Loss: 0.0133, Accuracy: 0.6439\n",
      "Epoch [187/100], Loss: 0.0134, Accuracy: 0.6451\n",
      "Epoch [188/100], Loss: 0.0133, Accuracy: 0.6427\n",
      "Epoch [189/100], Loss: 0.0133, Accuracy: 0.6361\n",
      "Epoch [190/100], Loss: 0.0133, Accuracy: 0.6530\n",
      "Epoch [191/100], Loss: 0.0133, Accuracy: 0.6542\n",
      "Epoch [192/100], Loss: 0.0133, Accuracy: 0.6433\n",
      "Epoch [193/100], Loss: 0.0133, Accuracy: 0.6355\n",
      "Epoch [194/100], Loss: 0.0133, Accuracy: 0.6457\n",
      "Epoch [195/100], Loss: 0.0133, Accuracy: 0.6494\n",
      "Epoch [196/100], Loss: 0.0133, Accuracy: 0.6488\n",
      "Epoch [197/100], Loss: 0.0132, Accuracy: 0.6494\n",
      "Epoch [198/100], Loss: 0.0132, Accuracy: 0.6554\n",
      "Epoch [199/100], Loss: 0.0132, Accuracy: 0.6512\n",
      "Epoch [200/100], Loss: 0.0132, Accuracy: 0.6482\n",
      "Test Accuracy: 0.5631\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_images_path = \"brain_train_image_final.npy\"\n",
    "train_labels_path = \"brain_train_label.npy\"\n",
    "test_images_path = \"brain_test_image_final.npy\"\n",
    "test_labels_path = \"brain_test_label.npy\"\n",
    "\n",
    "final_X_train_modified = np.load(train_images_path)[:, 1, :, :]  # Use second channel (grayscale)\n",
    "final_X_test_modified = np.load(test_images_path)[:, 1, :, :]  # Use second channel (grayscale)\n",
    "train_labels = np.load(train_labels_path)\n",
    "test_labels = np.load(test_labels_path)\n",
    "\n",
    "# Normalize and Resize Images using Pillow\n",
    "def normalize_and_resize(images, target_size=(224, 224)):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))  # Convert to PIL Image\n",
    "        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)  # Resize to target size using LANCZOS\n",
    "        resized_images.append(np.array(img_resized) / 255.0)  # Normalize back to [0, 1]\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Preprocess data\n",
    "final_X_train_resized = normalize_and_resize(final_X_train_modified, target_size=(224, 224))\n",
    "final_X_test_resized = normalize_and_resize(final_X_test_modified, target_size=(224, 224))\n",
    "\n",
    "# Define SimCLR Augmentation Transform for Grayscale Images\n",
    "transform_simclr = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(size=224),  # Random crop and resize\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),  # Color jitter\n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # Gaussian blur\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Custom Dataset Class for SimCLR\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, images, transform):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img_1 = self.transform(img)\n",
    "        img_2 = self.transform(img)\n",
    "        return img_1, img_2\n",
    "\n",
    "# Define SimCLR Model\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return z\n",
    "\n",
    "# Define NT-Xent Loss\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        N = z_i.size(0) + z_j.size(0)\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        sim = torch.matmul(z, z.T) / self.temperature\n",
    "        mask = ~torch.eye(N, dtype=torch.bool, device=z.device)\n",
    "\n",
    "        positives = torch.cat([\n",
    "            torch.diag(sim, z_i.size(0)),  # Sim between z_i and z_j\n",
    "            torch.diag(sim, -z_i.size(0)) # Sim between z_j and z_i\n",
    "        ])\n",
    "\n",
    "        negatives = sim[mask].view(N, -1)\n",
    "        logits = torch.cat((positives.unsqueeze(1), negatives), dim=1)\n",
    "        labels = torch.zeros(N, dtype=torch.long, device=z.device)\n",
    "        loss = self.criterion(logits, labels) / N\n",
    "        return loss\n",
    "\n",
    "# Initialize Dataset and DataLoader\n",
    "train_dataset = SimCLRDataset(final_X_train_resized, transform=transform_simclr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# Initialize Encoder and SimCLR Model\n",
    "base_encoder = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128 * 56 * 56, 512)\n",
    ")\n",
    "\n",
    "model = SimCLR(base_encoder, projection_dim=128).to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
    "criterion = NTXentLoss(batch_size=512, temperature=0.7)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(200):  # Number of epochs\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for img_1, img_2 in train_loader:\n",
    "        img_1, img_2 = img_1.to(\"cuda\"), img_2.to(\"cuda\")\n",
    "        z_i = model(img_1)\n",
    "        z_j = model(img_2)\n",
    "\n",
    "        loss = criterion(z_i, z_j)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/200], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save the Trained Model\n",
    "torch.save(model.state_dict(), \"simclr_model.pth\")\n",
    "\n",
    "# Evaluation on Test Dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        img_transformed = self.transform(img)\n",
    "        return img_transformed, label\n",
    "\n",
    "# Prepare test dataset and dataloader\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(final_X_test_resized, test_labels, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Classification Head\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Add Classification Head to Encoder\n",
    "classification_head = ClassificationHead(input_dim=512, num_classes=len(np.unique(train_labels))).to(\"cuda\")\n",
    "optimizer_cls = optim.Adam(classification_head.parameters(), lr=1e-3)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tune on Training Dataset\n",
    "for epoch in range(200):\n",
    "    model.eval()  # Freeze the encoder\n",
    "    classification_head.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for img, label in DataLoader(TestDataset(final_X_train_resized, train_labels, test_transform), batch_size=64, shuffle=True):\n",
    "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            features = model.encoder(img)\n",
    "        logits = classification_head(features)\n",
    "        loss = criterion_cls(logits, label)\n",
    "\n",
    "        optimizer_cls.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cls.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "    accuracy = correct / len(train_labels)\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_labels):.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate on Test Dataset\n",
    "classification_head.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
    "        features = model.encoder(img)\n",
    "        logits = classification_head(features)\n",
    "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "test_accuracy = correct / len(test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6746be-52f7-48d2-8183-e6dfa931a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 7.6340\n",
      "Epoch [2/100], Loss: 6.6477\n",
      "Epoch [3/100], Loss: 6.4410\n",
      "Epoch [4/100], Loss: 6.3400\n",
      "Epoch [5/100], Loss: 6.2405\n",
      "Epoch [6/100], Loss: 6.1682\n",
      "Epoch [7/100], Loss: 6.0574\n",
      "Epoch [8/100], Loss: 5.9719\n",
      "Epoch [9/100], Loss: 5.9086\n",
      "Epoch [10/100], Loss: 5.7387\n",
      "Epoch [11/100], Loss: 5.6313\n",
      "Epoch [12/100], Loss: 5.4963\n",
      "Epoch [13/100], Loss: 5.3828\n",
      "Epoch [14/100], Loss: 5.2629\n",
      "Epoch [15/100], Loss: 5.0523\n",
      "Epoch [16/100], Loss: 4.9362\n",
      "Epoch [17/100], Loss: 4.7863\n",
      "Epoch [18/100], Loss: 4.6578\n",
      "Epoch [19/100], Loss: 4.4885\n",
      "Epoch [20/100], Loss: 4.4764\n",
      "Epoch [21/100], Loss: 4.3528\n",
      "Epoch [22/100], Loss: 4.1687\n",
      "Epoch [23/100], Loss: 4.2206\n",
      "Epoch [24/100], Loss: 3.9252\n",
      "Epoch [25/100], Loss: 3.8786\n",
      "Epoch [26/100], Loss: 3.7276\n",
      "Epoch [27/100], Loss: 3.6913\n",
      "Epoch [28/100], Loss: 3.6383\n",
      "Epoch [29/100], Loss: 3.5958\n",
      "Epoch [30/100], Loss: 3.5365\n",
      "Epoch [31/100], Loss: 3.4605\n",
      "Epoch [32/100], Loss: 3.4075\n",
      "Epoch [33/100], Loss: 3.3468\n",
      "Epoch [34/100], Loss: 3.2655\n",
      "Epoch [35/100], Loss: 3.2160\n",
      "Epoch [36/100], Loss: 3.1232\n",
      "Epoch [37/100], Loss: 3.1971\n",
      "Epoch [38/100], Loss: 3.1870\n",
      "Epoch [39/100], Loss: 3.1555\n",
      "Epoch [40/100], Loss: 2.9830\n",
      "Epoch [41/100], Loss: 3.0170\n",
      "Epoch [42/100], Loss: 2.9676\n",
      "Epoch [43/100], Loss: 2.8215\n",
      "Epoch [44/100], Loss: 2.9198\n",
      "Epoch [45/100], Loss: 2.8737\n",
      "Epoch [46/100], Loss: 2.9375\n",
      "Epoch [47/100], Loss: 2.7696\n",
      "Epoch [48/100], Loss: 2.7808\n",
      "Epoch [49/100], Loss: 2.8974\n",
      "Epoch [50/100], Loss: 2.7901\n",
      "Epoch [51/100], Loss: 2.7375\n",
      "Epoch [52/100], Loss: 2.7295\n",
      "Epoch [53/100], Loss: 2.7896\n",
      "Epoch [54/100], Loss: 2.6698\n",
      "Epoch [55/100], Loss: 2.6085\n",
      "Epoch [56/100], Loss: 2.5813\n",
      "Epoch [57/100], Loss: 2.5682\n",
      "Epoch [58/100], Loss: 2.5818\n",
      "Epoch [59/100], Loss: 2.5700\n",
      "Epoch [60/100], Loss: 2.6179\n",
      "Epoch [61/100], Loss: 2.5656\n",
      "Epoch [62/100], Loss: 2.5975\n",
      "Epoch [63/100], Loss: 2.5484\n",
      "Epoch [64/100], Loss: 2.5571\n",
      "Epoch [65/100], Loss: 2.5644\n",
      "Epoch [66/100], Loss: 2.5288\n",
      "Epoch [67/100], Loss: 2.4949\n",
      "Epoch [68/100], Loss: 2.5266\n",
      "Epoch [69/100], Loss: 2.4467\n",
      "Epoch [70/100], Loss: 2.5279\n",
      "Epoch [71/100], Loss: 2.4200\n",
      "Epoch [72/100], Loss: 2.4129\n",
      "Epoch [73/100], Loss: 2.3483\n",
      "Epoch [74/100], Loss: 2.4725\n",
      "Epoch [75/100], Loss: 2.4378\n",
      "Epoch [76/100], Loss: 2.5019\n",
      "Epoch [77/100], Loss: 2.4971\n",
      "Epoch [78/100], Loss: 2.3714\n",
      "Epoch [79/100], Loss: 2.3599\n",
      "Epoch [80/100], Loss: 2.4728\n",
      "Epoch [81/100], Loss: 2.4163\n",
      "Epoch [82/100], Loss: 2.3311\n",
      "Epoch [83/100], Loss: 2.4253\n",
      "Epoch [84/100], Loss: 2.4228\n",
      "Epoch [85/100], Loss: 2.1551\n",
      "Epoch [86/100], Loss: 2.3293\n",
      "Epoch [87/100], Loss: 2.2287\n",
      "Epoch [88/100], Loss: 2.3075\n",
      "Epoch [89/100], Loss: 2.2134\n",
      "Epoch [90/100], Loss: 2.2265\n",
      "Epoch [91/100], Loss: 2.3912\n",
      "Epoch [92/100], Loss: 2.3205\n",
      "Epoch [93/100], Loss: 2.2834\n",
      "Epoch [94/100], Loss: 2.2698\n",
      "Epoch [95/100], Loss: 2.3170\n",
      "Epoch [96/100], Loss: 2.1274\n",
      "Epoch [97/100], Loss: 2.2007\n",
      "Epoch [98/100], Loss: 2.2200\n",
      "Epoch [99/100], Loss: 2.3230\n",
      "Epoch [100/100], Loss: 2.1390\n",
      "Epoch [1/100], Loss: 1.0256, Accuracy: 0.4550\n",
      "Epoch [2/100], Loss: 0.9088, Accuracy: 0.5631\n",
      "Epoch [3/100], Loss: 0.8352, Accuracy: 0.6132\n",
      "Epoch [4/100], Loss: 0.7601, Accuracy: 0.6783\n",
      "Epoch [5/100], Loss: 0.6858, Accuracy: 0.7254\n",
      "Epoch [6/100], Loss: 0.5988, Accuracy: 0.7827\n",
      "Epoch [7/100], Loss: 0.5012, Accuracy: 0.8298\n",
      "Epoch [8/100], Loss: 0.4243, Accuracy: 0.8684\n",
      "Epoch [9/100], Loss: 0.3244, Accuracy: 0.9197\n",
      "Epoch [10/100], Loss: 0.2552, Accuracy: 0.9427\n",
      "Epoch [11/100], Loss: 0.2022, Accuracy: 0.9656\n",
      "Epoch [12/100], Loss: 0.1727, Accuracy: 0.9734\n",
      "Epoch [13/100], Loss: 0.1560, Accuracy: 0.9747\n",
      "Epoch [14/100], Loss: 0.1311, Accuracy: 0.9843\n",
      "Epoch [15/100], Loss: 0.1106, Accuracy: 0.9909\n",
      "Epoch [16/100], Loss: 0.0924, Accuracy: 0.9970\n",
      "Epoch [17/100], Loss: 0.0798, Accuracy: 0.9964\n",
      "Epoch [18/100], Loss: 0.0676, Accuracy: 0.9982\n",
      "Epoch [19/100], Loss: 0.0580, Accuracy: 0.9988\n",
      "Epoch [20/100], Loss: 0.0515, Accuracy: 0.9988\n",
      "Epoch [21/100], Loss: 0.0465, Accuracy: 0.9988\n",
      "Epoch [22/100], Loss: 0.0401, Accuracy: 1.0000\n",
      "Epoch [23/100], Loss: 0.0396, Accuracy: 1.0000\n",
      "Epoch [24/100], Loss: 0.0346, Accuracy: 1.0000\n",
      "Epoch [25/100], Loss: 0.0381, Accuracy: 1.0000\n",
      "Epoch [26/100], Loss: 0.0305, Accuracy: 1.0000\n",
      "Epoch [27/100], Loss: 0.0311, Accuracy: 1.0000\n",
      "Epoch [28/100], Loss: 0.0285, Accuracy: 1.0000\n",
      "Epoch [29/100], Loss: 0.0266, Accuracy: 1.0000\n",
      "Epoch [30/100], Loss: 0.0254, Accuracy: 1.0000\n",
      "Epoch [31/100], Loss: 0.0236, Accuracy: 1.0000\n",
      "Epoch [32/100], Loss: 0.0241, Accuracy: 1.0000\n",
      "Epoch [33/100], Loss: 0.0228, Accuracy: 1.0000\n",
      "Epoch [34/100], Loss: 0.0208, Accuracy: 1.0000\n",
      "Epoch [35/100], Loss: 0.0219, Accuracy: 1.0000\n",
      "Epoch [36/100], Loss: 0.0214, Accuracy: 1.0000\n",
      "Epoch [37/100], Loss: 0.0191, Accuracy: 1.0000\n",
      "Epoch [38/100], Loss: 0.0193, Accuracy: 1.0000\n",
      "Epoch [39/100], Loss: 0.0178, Accuracy: 1.0000\n",
      "Epoch [40/100], Loss: 0.0187, Accuracy: 1.0000\n",
      "Epoch [41/100], Loss: 0.0178, Accuracy: 1.0000\n",
      "Epoch [42/100], Loss: 0.0180, Accuracy: 1.0000\n",
      "Epoch [43/100], Loss: 0.0164, Accuracy: 1.0000\n",
      "Epoch [44/100], Loss: 0.0178, Accuracy: 1.0000\n",
      "Epoch [45/100], Loss: 0.0169, Accuracy: 1.0000\n",
      "Epoch [46/100], Loss: 0.0164, Accuracy: 1.0000\n",
      "Epoch [47/100], Loss: 0.0171, Accuracy: 1.0000\n",
      "Epoch [48/100], Loss: 0.0158, Accuracy: 1.0000\n",
      "Epoch [49/100], Loss: 0.0150, Accuracy: 1.0000\n",
      "Epoch [50/100], Loss: 0.0157, Accuracy: 1.0000\n",
      "Epoch [51/100], Loss: 0.0147, Accuracy: 1.0000\n",
      "Epoch [52/100], Loss: 0.0151, Accuracy: 1.0000\n",
      "Epoch [53/100], Loss: 0.0143, Accuracy: 1.0000\n",
      "Epoch [54/100], Loss: 0.0149, Accuracy: 1.0000\n",
      "Epoch [55/100], Loss: 0.0140, Accuracy: 1.0000\n",
      "Epoch [56/100], Loss: 0.0146, Accuracy: 1.0000\n",
      "Epoch [57/100], Loss: 0.0137, Accuracy: 1.0000\n",
      "Epoch [58/100], Loss: 0.0165, Accuracy: 1.0000\n",
      "Epoch [59/100], Loss: 0.0138, Accuracy: 1.0000\n",
      "Epoch [60/100], Loss: 0.0138, Accuracy: 1.0000\n",
      "Epoch [61/100], Loss: 0.0147, Accuracy: 1.0000\n",
      "Epoch [62/100], Loss: 0.0146, Accuracy: 1.0000\n",
      "Epoch [63/100], Loss: 0.0139, Accuracy: 1.0000\n",
      "Epoch [64/100], Loss: 0.0145, Accuracy: 1.0000\n",
      "Epoch [65/100], Loss: 0.0134, Accuracy: 1.0000\n",
      "Epoch [66/100], Loss: 0.0149, Accuracy: 1.0000\n",
      "Epoch [67/100], Loss: 0.0141, Accuracy: 1.0000\n",
      "Epoch [68/100], Loss: 0.0136, Accuracy: 1.0000\n",
      "Epoch [69/100], Loss: 0.0138, Accuracy: 1.0000\n",
      "Epoch [70/100], Loss: 0.0132, Accuracy: 1.0000\n",
      "Epoch [71/100], Loss: 0.0141, Accuracy: 1.0000\n",
      "Epoch [72/100], Loss: 0.0129, Accuracy: 1.0000\n",
      "Epoch [73/100], Loss: 0.0134, Accuracy: 1.0000\n",
      "Epoch [74/100], Loss: 0.0131, Accuracy: 1.0000\n",
      "Epoch [75/100], Loss: 0.0139, Accuracy: 1.0000\n",
      "Epoch [76/100], Loss: 0.0135, Accuracy: 1.0000\n",
      "Epoch [77/100], Loss: 0.0146, Accuracy: 1.0000\n",
      "Epoch [78/100], Loss: 0.0135, Accuracy: 1.0000\n",
      "Epoch [79/100], Loss: 0.0134, Accuracy: 1.0000\n",
      "Epoch [80/100], Loss: 0.0132, Accuracy: 1.0000\n",
      "Epoch [81/100], Loss: 0.0139, Accuracy: 1.0000\n",
      "Epoch [82/100], Loss: 0.0136, Accuracy: 1.0000\n",
      "Epoch [83/100], Loss: 0.0139, Accuracy: 1.0000\n",
      "Epoch [84/100], Loss: 0.0137, Accuracy: 1.0000\n",
      "Epoch [85/100], Loss: 0.0131, Accuracy: 1.0000\n",
      "Epoch [86/100], Loss: 0.0135, Accuracy: 1.0000\n",
      "Epoch [87/100], Loss: 0.0126, Accuracy: 1.0000\n",
      "Epoch [88/100], Loss: 0.0130, Accuracy: 1.0000\n",
      "Epoch [89/100], Loss: 0.0134, Accuracy: 1.0000\n",
      "Epoch [90/100], Loss: 0.0122, Accuracy: 1.0000\n",
      "Epoch [91/100], Loss: 0.0126, Accuracy: 1.0000\n",
      "Epoch [92/100], Loss: 0.0128, Accuracy: 1.0000\n",
      "Epoch [93/100], Loss: 0.0135, Accuracy: 1.0000\n",
      "Epoch [94/100], Loss: 0.0148, Accuracy: 1.0000\n",
      "Epoch [95/100], Loss: 0.0136, Accuracy: 1.0000\n",
      "Epoch [96/100], Loss: 0.0135, Accuracy: 1.0000\n",
      "Epoch [97/100], Loss: 0.0134, Accuracy: 1.0000\n",
      "Epoch [98/100], Loss: 0.0133, Accuracy: 1.0000\n",
      "Epoch [99/100], Loss: 0.0131, Accuracy: 1.0000\n",
      "Epoch [100/100], Loss: 0.0125, Accuracy: 1.0000\n",
      "Test Accuracy: 0.8771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "train_images_path = \"brain_train_image_final.npy\"\n",
    "train_labels_path = \"brain_train_label.npy\"\n",
    "test_images_path = \"brain_test_image_final.npy\"\n",
    "test_labels_path = \"brain_test_label.npy\"\n",
    "\n",
    "# Load the data\n",
    "final_X_train_modified = np.load(train_images_path)[:, 1, :, :]\n",
    "final_X_test_modified = np.load(test_images_path)[:, 1, :, :]\n",
    "train_labels = np.load(train_labels_path)\n",
    "test_labels = np.load(test_labels_path)\n",
    "\n",
    "# Normalize and Resize Images using Pillow\n",
    "def normalize_and_resize(images, target_size=(224, 224)):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        resized_images.append(np.array(img_resized) / 255.0)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "final_X_train_resized = normalize_and_resize(final_X_train_modified)\n",
    "final_X_test_resized = normalize_and_resize(final_X_test_modified)\n",
    "\n",
    "# Define SimCLR Augmentation Transform\n",
    "transform_simclr = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset for SimCLR\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, images, transform):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img_1 = self.transform(img)\n",
    "        img_2 = self.transform(img)\n",
    "        return img_1, img_2\n",
    "\n",
    "train_dataset = SimCLRDataset(final_X_train_resized, transform_simclr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# Define SimCLR Model\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return z\n",
    "\n",
    "# Define NT-Xent Loss\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        N = z_i.size(0) + z_j.size(0)\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        sim = torch.matmul(z, z.T) / self.temperature\n",
    "        mask = ~torch.eye(N, dtype=torch.bool, device=z.device)\n",
    "\n",
    "        positives = torch.cat([\n",
    "            torch.diag(sim, z_i.size(0)),\n",
    "            torch.diag(sim, -z_i.size(0))\n",
    "        ])\n",
    "\n",
    "        negatives = sim[mask].view(N, -1)\n",
    "        logits = torch.cat((positives.unsqueeze(1), negatives), dim=1)\n",
    "        labels = torch.zeros(N, dtype=torch.long, device=z.device)\n",
    "        loss = self.criterion(logits, labels) / N\n",
    "        return loss\n",
    "\n",
    "# Initialize ResNet-18 Encoder\n",
    "base_encoder = resnet18(pretrained=True)\n",
    "base_encoder.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "base_encoder.fc = nn.Identity()\n",
    "\n",
    "# Initialize SimCLR Model\n",
    "model = SimCLR(base_encoder, projection_dim=128).to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = NTXentLoss(batch_size=512, temperature=0.5)\n",
    "\n",
    "# Train SimCLR Model\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for img_1, img_2 in train_loader:\n",
    "        img_1, img_2 = img_1.to(\"cuda\"), img_2.to(\"cuda\")\n",
    "        z_i = model(img_1)\n",
    "        z_j = model(img_2)\n",
    "\n",
    "        loss = criterion(z_i, z_j)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Define Dataset for Classification\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Initialize Training and Test Dataset and DataLoader\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset = TestDataset(final_X_train_resized, train_labels, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "test_dataset = TestDataset(final_X_test_resized, test_labels, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Add Classification Head\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "classification_head = ClassificationHead(input_dim=512, num_classes=len(np.unique(train_labels))).to(\"cuda\")\n",
    "optimizer_cls = optim.Adam([\n",
    "    {\"params\": model.encoder.parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "scheduler_cls = StepLR(optimizer_cls, step_size=10, gamma=0.5)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tune Classification Head\n",
    "for epoch in range(100):\n",
    "    model.encoder.train()\n",
    "    classification_head.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for img, label in DataLoader(train_dataset, batch_size=128, shuffle=True):\n",
    "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
    "        features = model.encoder(img)\n",
    "        logits = classification_head(features)\n",
    "        loss = criterion_cls(logits, label)\n",
    "\n",
    "        optimizer_cls.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cls.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "    accuracy = correct / len(train_labels)\n",
    "    scheduler_cls.step()\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate on Test Dataset\n",
    "classification_head.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in DataLoader(test_dataset, batch_size=128, shuffle=False):\n",
    "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
    "        features = model.encoder(img)\n",
    "        logits = classification_head(features)\n",
    "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "test_accuracy = correct / len(test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077659e6-26ef-4229-8eec-b15836c9faa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "train_images_path = \"brain_train_image_final.npy\"\n",
    "train_labels_path = \"brain_train_label.npy\"\n",
    "test_images_path = \"brain_test_image_final.npy\"\n",
    "test_labels_path = \"brain_test_label.npy\"\n",
    "\n",
    "# Load the data\n",
    "final_X_train_modified = np.load(train_images_path)[:, 1, :, :]\n",
    "final_X_test_modified = np.load(test_images_path)[:, 1, :, :]\n",
    "train_labels = np.load(train_labels_path)\n",
    "test_labels = np.load(test_labels_path)\n",
    "\n",
    "# Normalize and Resize Images using Pillow\n",
    "def normalize_and_resize(images, target_size=(224, 224)):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        resized_images.append(np.array(img_resized) / 255.0)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "final_X_train_resized = normalize_and_resize(final_X_train_modified)\n",
    "final_X_test_resized = normalize_and_resize(final_X_test_modified)\n",
    "\n",
    "# Define SimCLR Augmentation Transform\n",
    "transform_simclr = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.08, 1.0), ratio=(3/4, 4/3)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0))], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset for SimCLR\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, images, transform):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img_1 = self.transform(img)\n",
    "        img_2 = self.transform(img)\n",
    "        return img_1, img_2\n",
    "\n",
    "train_dataset = SimCLRDataset(final_X_train_resized, transform_simclr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# Define SimCLR Model\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return z\n",
    "\n",
    "# Define NT-Xent Loss\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        N = z_i.size(0) + z_j.size(0)\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        sim = torch.mm(z, z.T) / self.temperature\n",
    "        sim = torch.nn.functional.softmax(sim, dim=1)\n",
    "\n",
    "        labels = torch.cat([\n",
    "            torch.arange(z_i.size(0), device=z.device),\n",
    "            torch.arange(z_j.size(0), device=z.device)\n",
    "        ])\n",
    "        loss = self.criterion(sim, labels)\n",
    "        return loss\n",
    "\n",
    "# Initialize ResNet-50 Encoder\n",
    "base_encoder = resnet50(pretrained=True)\n",
    "base_encoder.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "base_encoder.fc = nn.Identity()\n",
    "\n",
    "# Initialize SimCLR Model\n",
    "model = SimCLR(base_encoder, projection_dim=128).to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = NTXentLoss(temperature=0.5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# Train SimCLR Model\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for img_1, img_2 in train_loader:\n",
    "        img_1, img_2 = img_1.to(\"cuda\"), img_2.to(\"cuda\")\n",
    "        z_i = model(img_1)\n",
    "        z_j = model(img_2)\n",
    "\n",
    "        loss = criterion(z_i, z_j)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Define Dataset for Classification\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Initialize Training and Test Dataset and DataLoader\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset = TestDataset(final_X_train_resized, train_labels, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TestDataset(final_X_test_resized, test_labels, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Add Classification Head\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "classification_head = ClassificationHead(input_dim=2048, num_classes=len(np.unique(train_labels))).to(\"cuda\")\n",
    "optimizer_cls = optim.Adam([\n",
    "    {\"params\": model.encoder.parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": classification_head.parameters(), \"lr\": 3e-4},\n",
    "])\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tune Classification Head\n",
    "for epoch in range(100):\n",
    "    model.encoder.train()\n",
    "    classification_head.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for img, label in train_loader:\n",
    "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
    "        features = model.encoder(img)\n",
    "        logits = classification_head(features)\n",
    "        loss = criterion_cls(logits, label)\n",
    "\n",
    "        optimizer_cls.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cls.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "    accuracy = correct / len(train_labels)\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate on Test Dataset\n",
    "classification_head.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(\"cuda\"), label.to(\"cuda\")\n",
    "        features = model.encoder(img)\n",
    "        logits = classification_head(features)\n",
    "        correct += (logits.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "test_accuracy = correct / len(test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02c46d-9376-4d7b-97b7-a4d02a4c70bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
